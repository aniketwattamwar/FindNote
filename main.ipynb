{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    }
   ],
   "source": [
    "#Google API key: AIzaSyApFClW1eAeWob3reV89-3EqQFUjKN6GDE\n",
    "#OpenAI API Key: sk-proj-thuLLA3cF6zKQldvkRNaT3BlbkFJvbZd8OGdD1ZCXMcCrZyR\n",
    "\n",
    "# ! pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyApFClW1eAeWob3reV89-3EqQFUjKN6GDE\")\n",
    "# The Gemini 1.5 models are versatile and work with both text-only and multimodal prompts\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 stories in 10 words each:\n",
      "\n",
      "1. **Lost in the woods, found a friend.**\n",
      "2. **The old clock ticked, time stood still.**\n",
      "3. **One wish granted, forever changed.**\n",
      "4. **Stars whispered secrets, moon listened close.**\n",
      "5. **A single tear, a lifetime of pain.**\n",
      "6. **The book opened, a world unfolded.**\n",
      "7. **He built a bridge, over the divide.**\n",
      "8. **The silence screamed, louder than words.**\n",
      "9. **He chased the sunset, never to return.**\n",
      "10. **The last leaf fell, winter's embrace.** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"Write a story in 10 words. Give 10 stories\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyApFClW1eAeWob3reV89-3EqQFUjKN6GDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-thought:\n",
      "First find the total number of cats: 3 houses * 3 cats / house = 9 cats. Then multiply the number of cats by the number of mittens per cat to find the total number of mittens: 9 cats * 4 mittens / cat = 36 mittens. Then multiply the number of mittens by the length of yarn per mitten to find the total length of yarn used for mittens: 36 mittens * 7m / mitten = 252m. Then multiply the number of cats by the number of hats per cat to find the total number of hats: 9 cats * 1 hat / cat = 9 hats. Then multiply the number of hats by the length of yarn per hat to find the total length of yarn used for hats: 9 hats * 4m / hat = 36m. Then add the length of yarn used for mittens and hats to find the total length of yarn used: 252m + 36m = 288m.\n",
      "\n",
      "The answer should be 288\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert at solving word problems.\n",
    "\n",
    "Solve the following problem:\n",
    "\n",
    "I have three houses, each with three cats.\n",
    "each cat owns 4 mittens, and a hat. Each mitten was\n",
    "knit from 7m of yarn, each hat from 4m.\n",
    "How much yarn was needed to make all the items?\n",
    "\n",
    "Think about it step by step, and show your work.\n",
    "\"\"\"\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "\n",
    "api_key = \"AIzaSyApFClW1eAeWob3reV89-3EqQFUjKN6GDE\"\n",
    "llm = GooglePalm(google_api_key=api_key, temperature=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Death Note (2006)\n",
      "2. Monster (2004)\n",
      "3. Steins;Gate (2011)\n",
      "4. Code Geass: Lelouch of the Rebellion (2006)\n",
      "5. Psycho-Pass (2012)\n"
     ]
    }
   ],
   "source": [
    "anime = llm(\"Anime top 5 based on thriller\")\n",
    "print(anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.text_splitter import SemanticChunker\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = SemanticChunker(OpenAIEmbeddings(api_key=\"sk-proj-thuLLA3cF6zKQldvkRNaT3BlbkFJvbZd8OGdD1ZCXMcCrZyR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"content.txt\", encoding = 'UTF-8')\n",
    "document = loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0438980758190155,\n",
       " 0.007685545831918716,\n",
       " -0.009231897071003914,\n",
       " 0.024496247991919518,\n",
       " 0.033592283725738525]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")\n",
    "e[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\",\"\\n\\n\",\".\"]\n",
    ")\n",
    "\n",
    "# As data is of type documents we can directly use split_documents over split_text in order to get the chunks.\n",
    "docs = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Job Msg Format Section\\nThursday, February 23, 2023\\n10:38 AM\\n\\nContact email:\\nMcGraw Hill: \\nPlease contact us if you need assistance with the application process: talentacquisition@mheducation.com\\n\\nCold Email/Msg Format:\\n\\nHello,\\n\\nMy name is Aniket Wattamwar currently pursuing my Masters in Computer Science from California State University, Fullerton. I am looking for summer’23 internship in software engineering.\\n\\nMy skills are in Python and Full stack Development. I have completed projects in AWS, flask, Django with MySQL Database. I am passionate about learning new technologies and solving problems.\\n\\nI wish to apply for the software engineering intern position at your organization to enhance my skills and contribute to the mission and vision.\\n\\nAttaching my resume for your reference.\\nYou can have a look at my portfolio as well:\\nhttps://aniketwattamwar.netlify.app/\\n\\nThanks,\\nAniket\\n\\n——————————————————\\n\\nHi,\\n\\n\\nHope you are doing well.', metadata={'source': 'content.txt'})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Attaching my resume for your reference.\\nYou can have a look at my portfolio as well:\\nhttps://aniketwattamwar.netlify.app/\\n\\nThanks,\\nAniket\\n\\n——————————————————\\n\\nHi,\\n\\n\\nHope you are doing well.\\nI am pursuing my Masters from CSU,Fullerton in CS & came across an opening at _______ for software engineer intern and I was wondering if you would be open to referring me for the same.\\nMy portfolio & resume: https://aniketwattamwar.netlify.app/\\n\\nThanks,\\nAniket\\n\\n———————————\\n\\nHi \\n\\nI am pursuing my Masters from California State University, Fullerton in CS. \\nand wish to connect with you.\\n\\nThanks,\\nAniket\\nPortfolio: https://aniketwattamwar.netlify.app/\\n\\n__________\\n\\n“Hey John. Just noticed that we have a mutual connection in Matthew. I love what you’re doing at XYZ Company and would love to connect.”\\n\\n\\nHello,\\nI came across your profile and noticed we share many mutual connections. Your area of expertise in ML aligns with my interest and would love to connect.\\n\\nThanks,\\nAniket', metadata={'source': 'content.txt'})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = Neo4jVector.from_documents(\n",
    "#     docs, instructor_embeddings, url=url, username=username, password=password\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=docs,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Watch Section\\n\\nSaturday, February 25, 2023\\n7:41 PM\\n\\n\\nThe Queens Gambit\\nThe elephant whisperers\\nStranger\\nLiving with yourself\\nLittle woman\\nExtraordinary on Hulu\\nAbove the shadows movie\\nMarie Kondo - suggested by sarah\\nThe age of adaline\\nTomb raider\\nDetachment\\nCatch me if you can\\n12 years a slave\\nCurious case of benjamin button\\n secret life of walter mitty\\nKings of summer\\nDead poet's society\\nThe pianist\\nBeautiful life\\nGood will hunting\\nBeautiful mind\\nBig short\\nEx machina\\nThe last dance\\nBridge of terabithia\\nTu hai mera Sunday\\nBazaar - netflix\\nDetective byomkesh bakshi\\nNewton\\nGrowing up smith\\nTruman show\\n7 years in tibet\\n\\nAnime:\\n\\nJujutsu Kaisen\\nGhibli stories: whisper of the heart\\nA silent voice\\nYour lie in April\\nGrave of the fireflies\\nAnohana\\nMoriarity the patriot\\nBlack lagoon\\nDarker than black\\nTerror in resonance\\nInuyashiki\\nRecord of ragnarok\\nThe daily life of immortal king\\n\\n\\nHulu:\\nabhius9644@gmail.com\\nHulu$456\\n\\nRewatch:\", metadata={'source': 'content.txt'}),\n",
       " Document(page_content='I am also a writer on Towards Data Science, Analytics Vidhya on Medium. Since I have made considerable amount of YouTube content on AWS, Python I was selected for the AWS Community Builder Program for 2 years now.  I am also a teaching associate for frontend technologies course in my University teaching undergraduate students.', metadata={'source': 'content.txt'}),\n",
       " Document(page_content='Hulu:\\nabhius9644@gmail.com\\nHulu$456\\n\\nRewatch:\\n\\nPatiala House\\nChakde india\\nSwades \\nSilent of the lambs \\nPiku\\nDil toh baccha hai ji\\nBhagam bhag \\n\\n\\nLeetcode Algo - Feymann Technique Section\\n\\nSunday, February 26, 2023\\n7:04 PM', metadata={'source': 'content.txt'}),\n",
       " Document(page_content='I would like to discuss more on a call if that’s possible. I am in the Pacific(PDT) time. Do let me know your availability and we can discuss further.\\n\\nAniket  \\n\\n3d Printing Section\\n\\nFriday, October 27, 2023\\n11:40 AM\\n\\n\\n2525\\n\\n\\n\\nDragon Ball Keychain\\nToothepaste squeezer\\nbook page holder\\ncan holder\\nFinger Shield\\ntic tac toe\\nquoridor\\nButtons\\nFlying propeller\\nAtm card holder\\nMecrricco catch - page turing finger tips\\nBath glass shower hook\\nAnytime tongs\\nFoldable crate\\nSnorlax\\n\\nPackaging design', metadata={'source': 'content.txt'})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"Is there anything about anime\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What was the technique for adding two numbers',\n",
       " 'result': 'Take carry, l1val l2val and know how to use total%10 and total//10',\n",
       " 'source_documents': [Document(page_content='502. IPO\\tMake capital profit vector and use max heap to store max profit. So every time u pop u get max proft and add to w to get final ans\\n198. House Robber \\tCreate a 1d DP array. Choose the current and two places behind money or just the prev one whichever is greater and return the last dp value\\n120. Triangle\\tUsing DP. Start from bottom and just add minimum of upper value and upper right value. Ans will be at 0,0\\n64. Minimum Path Sum\\tUse 2d DP and add previous minimum value with current grid value\\n63. Unique Paths II\\tUse 2d DP with obstacle changing to 0 when see it and others changing/adding to the current value\\n97. Interleaving String\\tUse 2d dp. Rows cols is s1 and s2 and compare each position with s3 value. Tricky question to visulize', metadata={'source': 'content.txt'}),\n",
       "  Document(page_content='205. Isomorphic Strings\\tCreate two dict and match the values. If same then true else false.\\n179. Largest Number\\tBasically a sorting problem, but need to write your own sorting logic. Convert to strings and join current number with next and check which is larger. If larger then swap else pass. Do this for all numbers. TC is O(n^2)\\n135. Candy\\t\\n221. Maximal Square\\tUsing DP. Check each cell as the end of a square and take the minimum in up, left, and backward diagonal.', metadata={'source': 'content.txt'}),\n",
       "  Document(page_content='4. Median of two sorted arrays\\tUse Two pointers or binary search to solve.\\n805. Split array with same avg\\tCalculate total sum and avg, then look for a  subset of numbers whose avg is close to half of the total avg. If found return True since the second subset avg will be equal. Uses a possible sets dict/set to find all sets and then look for avg half to the total.\\n1895. Largest Magic Square\\t\\n287. Find duplicate number\\tTo adhere to the conditions and solving the problem --> Use Floyds cycle detection algorithm i.e slow-fast pointer approach\\n547. Number of Provinces\\tDo dfs. You just have to check if from any city i  how many j are connected with i,j as 1. Doable problem in interview if you understand the question.\\n205. Isomorphic Strings\\tCreate two dict and match the values. If same then true else false.', metadata={'source': 'content.txt'}),\n",
       "  Document(page_content='289. Game of life\\tUse bit encoding type of solution to save state, like 0->1 then 2, 1->1 will be 3.\\n48. Rotate Image\\tDo swapping and reverse the matrix\\n54. Spiral Matrix\\tTake 4 variables and individual create the spiral matrix\\n56. Merge Intervals\\tInterval problm so make a timeline for better chances of solving problem.\\n\\tSort and iterate while checking prev end and curr start, if true then change interval else not\\n57. Insert Interval\\tTake min of starts and max of ends to insert\\n150. Eval RPN\\tTake stack and pop elements when expression is found and calculate to push stack val back to stack\\n224. Basic Calculator\\tTake sign, stack, res. Keep track of sign and res in a list. Pop them and multiple sign and add the other value\\n2. Add Two Numbers\\tTake carry, l1val l2val and know how to use total%10 and total//10\\n92. Reversed Linked List\\tHard to code, but came up with logic.\\n\\tTake a dummy node at start to handle edge cases also. Go till left then reverse till Right and adjust the pointers', metadata={'source': 'content.txt'})]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain('What was the technique for adding two numbers') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
